{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset\n",
    "\n",
    "Import the preprocessed data set, which was preprocessed in the `data_preparation.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston = pd.read_csv('./data/prepared/rides_data_prepared.csv', index_col=0, dtype={'start_station_id': np.int64, 'end_station_id': 'string', 'end_station_name': 'string', 'start_station_name': 'string', 'bike_id': np.int64, 'user_type': 'string'})\n",
    "df_boston['start_time'] = pd.to_datetime(df_boston['start_time'], format='%Y-%m-%d %X')\n",
    " \n",
    "df_boston.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data set\n",
    "### Calculate Demand per Hour\n",
    "\n",
    "First of all, it is necessary to transform the data set such that we obtain a time series with hourly frequency and providing the demand for bike rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand = df_boston.resample(rule='H', on='start_time').size().reset_index(name='demand')\n",
    "df_demand.columns = ['date_time', 'demand']\n",
    "df_demand.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include Weather Data\n",
    "Now that the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv('./data/weather_hourly_boston.csv')\n",
    "df_weather['date_time'] = pd.to_datetime(df_weather['date_time'], format='%Y-%m-%d %X')\n",
    "df_demand = df_demand.merge(df_weather, how = 'left', on = 'date_time')\n",
    "df_demand.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous demand as input\n",
    "\n",
    "As we have given time series data, it is a common approach to use the demand from previous hours (or days etc.) as an input for the prediction. The assumption we hereby make is that the factors that influence the demand have not changed dramatically within the last hours. We have decided to use the demand of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand['demand_h-1'] = df_demand.demand.shift(periods=11)\n",
    "df_demand['demand_h-2'] = df_demand.demand.shift(periods=2)\n",
    "df_demand['demand_h-24'] = df_demand.demand.shift(periods=24)\n",
    "df_demand['demand_w-1'] = df_demand.demand.shift(periods=168)\n",
    "df_demand['demand_average_w-1'] = df_demand.rolling(window=168, on='demand')\n",
    "df_demand.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand['avg_temp'] = (df_demand.min_temp + df_demand.max_temp)/2\n",
    "df_demand['avg_temp_dev'] = df_demand['avg_temp'] - df_demand['avg_temp'].mean()\n",
    "df_demand.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature change within hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand['temp_change'] = df_demand.min_temp - df_demand.max_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_season(row):\n",
    "    if row.date_time < datetime(2015,3,20):\n",
    "        return 'winter'\n",
    "    elif row.date_time >= datetime(2015,3,20) and row.date_time < datetime(2015,6,21):\n",
    "        return 'spring'\n",
    "    elif row.date_time >= datetime(2015,6,21) and row.date_time < datetime(2015,9,23):\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "df_demand['season'] = df_demand.apply((lambda x: determine_season(x)), axis=1)\n",
    "df_demand = pd.get_dummies(df_demand, columns=['season'])\n",
    "df_demand.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date and time features\n",
    "df_demand['date'] = df_demand['date_time'].dt.strftime('%Y-%m-%d %X').apply(lambda x: x.split()[0])\n",
    "df_demand['hour'] = df_demand['date_time'].dt.strftime('%Y-%m-%d %X').apply(lambda x: int(x.split()[1].split(':')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekend feature\n",
    "In the descriptive analysis we have seen that on saturday and sunday the demand particularly low, hence we engineer a feature \"weekend\" which is 1 for all rides on saturday & sunday and zero for all other days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_weekend(row):\n",
    "    if row.date_time.weekday() > 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_demand['weekend'] = df_demand.apply((lambda x: determine_weekend(x)), axis=1)\n",
    "df_demand.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daytime features\n",
    "Further the descriptive analysis has shown that the daytime, i.e. if it is night, morning, afternoon or evening, plays an important role for the demand. Hence, we engineer four features that respectively indicate if a rides takes place during\n",
    "* Morning: 6am - 12pm\n",
    "* Afternoon: 12pm - 6pm\n",
    "* Evening: 6pm - 11pm\n",
    "* Night: 12am - 6am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_of_day = [\"morning\", \"afternoon\", \"evening\", \"night\"]\n",
    "morning_hours = [*range(6, 12)]\n",
    "afternoon_hours = [*range(12, 18)]\n",
    "evening = [*range(18, 23)]\n",
    "night = [23] + [*range(0, 6)]\n",
    "\n",
    "\n",
    "def get_point_of_day(hour):\n",
    "    if hour in morning_hours:\n",
    "        return \"morning\"\n",
    "    elif hour in afternoon_hours:\n",
    "        return \"afternoon\"\n",
    "    elif hour in evening:\n",
    "        return \"evening\"\n",
    "    elif hour in night:\n",
    "        return \"night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand['daytime'] = df_demand[\"date_time\"].dt.hour.apply(lambda x: get_point_of_day(x))\n",
    "df_demand = pd.get_dummies(df_demand, columns=['daytime'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Feature\n",
    "\n",
    "There were several public holidays in Boston:\n",
    "* New Year's Day: Friday, January 1\n",
    "* Martin Luther King Jr. Day: Monday, January 19\n",
    "* Presidents' Day: Monday, February 16\n",
    "* Patriots' Day: Monday, April 20\n",
    "* Memorial Day: Monday, May 25\n",
    "* Independence Day: Saturday, July 4\n",
    "* Labor Day: Monday, September 7\n",
    "* Columbus Day: Monday, October 12\n",
    "* Veterans Day: Wednesday, November 11\n",
    "* Thanksgiving Day: Thursday, November 26\n",
    "* Christmas Day: Friday, December 25\n",
    "\n",
    "These events might have influenced the demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_dates = [datetime(2015,1,1), datetime(2015,1,19), datetime(2015,2,16), datetime(2015,4,20),datetime(2015,5,25), datetime(2015,7,4), datetime(2015,9,7), datetime(2015,10,12), datetime(2015,11,11), datetime(2015,11,26), datetime(2015,12,25)]\n",
    "\n",
    "df_demand['public_holiday'] = df_demand.apply((lambda x: 1 if x.date_time in holiday_dates else 0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_demand.corr()\n",
    "top_corr_features = corr_matrix.index\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "sns.heatmap(df_demand[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['date_time', 'max_temp', 'min_temp', 'precip', 'demand_h-1',\n",
    "       'demand_h-2', 'demand_h-24', 'avg_temp', 'avg_temp_dev', 'temp_change',\n",
    "       'season_autumn', 'season_spring', 'season_winter', 'date', 'hour',\n",
    "       'weekend', 'daytime_afternoon', 'daytime_evening', 'daytime_morning',\n",
    "       'daytime_night']\n",
    "target = 'demand'\n",
    "\n",
    "X = df_demand[features]\n",
    "y = df_demand[target]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "model.fit(X,y)\n",
    "predicted =\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e82457f189db053704b58d76fff74fe99d1d788aac8c0d71f1d4ecc57efc9dbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
